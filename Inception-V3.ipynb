{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"inception-v3-springer-paper-2.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["from tensorflow import keras\n","from keras.models import Model\n","from keras import layers\n","from keras.layers import Dense, Input, BatchNormalization, Activation\n","from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n","#from keras.applications.imagenet_utils import _obtain_input_shape\n","from keras.utils.data_utils import get_file\n","\n","from keras.datasets import mnist\n","from PIL import Image\n","# for creating a one hot vector for labels\n","from keras.utils import np_utils\n","from IPython.display import display, Image\n","#import the models\n","from keras import Model\n","#add layers\n","from keras import layers\n","#add optimizer\n","from keras import optimizers\n","#add loss function \n","from keras import losses\n","\n","import keras\n","import numpy as np\n","import pandas as pd \n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n"," "],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T12:46:25.112381Z","iopub.execute_input":"2022-01-09T12:46:25.112923Z","iopub.status.idle":"2022-01-09T12:46:30.931211Z","shell.execute_reply.started":"2022-01-09T12:46:25.112830Z","shell.execute_reply":"2022-01-09T12:46:30.930388Z"},"trusted":true,"id":"9josb1aOrPI6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Source : https://github.com/RayXie29/Keras-famous_CNN/blob/master/InceptionV3.py"],"metadata":{"id":"iOb6BMq0rWbM"}},{"cell_type":"code","source":["import keras\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.layers import Dense, BatchNormalization, Activation\n","from keras.layers import Flatten, Input, concatenate, Dropout\n","from keras.regularizers import  l2\n","from keras import backend as K\n","from keras.models import Model\n","\n","img_size = 299\n","\n","class Inceptionv3_builder():\n","\n","    def __init__(self, input_shape = (img_size , img_size ,3), output_units = 1000, init_strides = (2,2),\n","                 regularizer = l2(1e-4), initializer = \"he_normal\", init_maxpooling = True):\n","\n","        '''\n","        :param input_shape: input shape of dataset\n","        :param output_units: output result dimension\n","        :param init_strides: The strides for first convolution layer\n","        :param regularizer: regularizer for all the convolution layers in whole NN\n","        :param initializer: weight/parameters initializer for all convolution & fc layers in whole NN\n","        :param init_maxpooling: Do the maxpooling after first two convolution layers or not\n","        '''\n","\n","        assert len(input_shape) == 3, \"input shape should be dim 3 ( row, col, channel or channel row col )\"\n","\n","        self.input_shape = input_shape\n","        self.output_units = output_units\n","        self.init_strides = init_strides\n","        self.regularizer = regularizer\n","        self.initializer = initializer\n","        self.init_maxpooling = init_maxpooling\n","\n","        #if K.image_dim_ordering() == \"tf\":\n","\n","        self.row_axis = 1\n","        self.col_axis = 2\n","        self.channel_axis = 3\n","        \"\"\"\n","\n","        else:\n","\n","            self.row_axis = 2\n","            self.col_axis = 3\n","            self.channel_axis = 1\n","        \"\"\"\n","\n","    def _cn_bn_relu(self, filters = 32, kernel_size = (3,3), strides = (1,1), padding = \"same\"):\n","        '''\n","        convenient function to build convolution -> batch_nromalization -> relu activation layers\n","        '''\n","        def f(input_x):\n","\n","            x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n","                       kernel_regularizer=self.regularizer,kernel_initializer=self.initializer)(input_x)\n","            x = BatchNormalization(axis=self.channel_axis)(x)\n","            x = Activation(\"relu\")(x)\n","\n","            return x\n","\n","        return f\n","\n","    def _auxiliary(self, name = \"auxiliary_1\"):\n","        '''\n","        In author's explanation:\n","        \" The auxiliary classifier will encourage discrimination in lower stages in the classifier,\n","        increase the gradient signal that gets propagated back, and provide additional regularization\"\n","        :return: An output layer of auxiliary classifier\n","        '''\n","        def f(input_x):\n","\n","            x = AveragePooling2D(pool_size=(5,5), strides = (3,3), padding = \"same\")(input_x)\n","            x = self._cn_bn_relu(filters = 128, kernel_size = (5,5), strides = (1,1), padding = \"same\")(x)\n","            x = Flatten()(x)\n","            x = Dense(units = 1024, kernel_initializer = self.initializer)(x)\n","            x = BatchNormalization(axis = 1)(x)\n","            x = Activation(\"relu\")(x)\n","            x = Dropout(0.7)(x)\n","\n","            return Dense(units = 3 , activation = \"softmax\", kernel_initializer=self.initializer, name = name)(x)\n","\n","        return f\n","\n","\n","    def _inception_block35x35(self,_1x1 = 64, _3x3r = 48, _3x3 = 64, _d3x3r = 64, _d3x3 = 96, _pool = 64, name = \"inception_fig5_1\"):\n","        '''\n","        A function for building inception block of figure5 in original article,\n","        '''\n","        def f(input_x):\n","\n","            branch1x1 = self._cn_bn_relu(filters = _1x1, kernel_size = (1,1))(input_x)\n","\n","            branchpooling = AveragePooling2D(pool_size=(3,3), strides = (1,1), padding = \"same\")(input_x)\n","            branchpooling = self._cn_bn_relu(filters = _pool, kernel_size = (1,1))(branchpooling)\n","\n","            branch3x3 = self._cn_bn_relu(filters = _3x3r, kernel_size = (1,1))(input_x)\n","            branch3x3 = self._cn_bn_relu(filters = _3x3, kernel_size = (3,3))(branch3x3)\n","\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3r, kernel_size = (1,1))(input_x)\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3, kernel_size = (3,3))(dbranch3x3)\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3, kernel_size = (3,3))(dbranch3x3)\n","\n","            return concatenate([branch1x1, branchpooling, branch3x3, dbranch3x3], axis = self.channel_axis, name = name)\n","\n","        return f\n","\n","    def _GridSizeReduction35x35(self, _3x3r = 288, _3x3 = 384, _d3x3r = 64, _d3x3 = 96):\n","        '''\n","        A function for dimension reducing from 35x35 -> 17x17\n","        '''\n","        def f(input_x):\n","\n","            branchpool = AveragePooling2D(pool_size=(3,3), strides = (2,2), padding = \"valid\")(input_x)\n","\n","            branch3x3 = self._cn_bn_relu(filters = _3x3r, kernel_size = (1,1))(input_x)\n","            branch3x3 = self._cn_bn_relu(filters = _3x3,  kernel_size = (3,3), strides = (2,2), padding = \"valid\")(branch3x3)\n","\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3r, kernel_size = (1,1))(input_x)\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3,  kernel_size = (3,3))(dbranch3x3)\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3,  kernel_size = (3,3), strides = (2,2), padding = \"valid\")(dbranch3x3)\n","\n","            return concatenate([branchpool, branch3x3, dbranch3x3], axis = self.channel_axis)\n","\n","        return f\n","\n","    def _inception_block17x17(self, _1x1 = 192, _7x7r = 128, _7x7 = 192, _d7x7r = 128, _d7x7 = 192, _pool = 192, name = \"inception_fig6_1\"):\n","        '''\n","        A function for building inception block of figure6 in original article,\n","        '''\n","        def f(input_x):\n","\n","            branch1x1 = self._cn_bn_relu(filters=_1x1, kernel_size=(1, 1))(input_x)\n","\n","            branchpooling = AveragePooling2D(pool_size = (3,3), strides = (1,1), padding = \"same\")(input_x)\n","            branchpooling = self._cn_bn_relu(filters = _pool, kernel_size = (1,1))(branchpooling)\n","\n","            branch7x7 = self._cn_bn_relu(filters = _7x7r, kernel_size = (1,1))(input_x)\n","            branch7x7 = self._cn_bn_relu(filters = _7x7r, kernel_size = (7,1))(branch7x7)\n","            branch7x7 = self._cn_bn_relu(filters = _7x7, kernel_size=(1, 7))(branch7x7)\n","\n","            dbranch7x7 = self._cn_bn_relu(filters = _d7x7r, kernel_size = (1,1))(input_x)\n","            for i in range(2):\n","                dbranch7x7 = self._cn_bn_relu(filters = _d7x7r, kernel_size=(7, 1))(branch7x7)\n","\n","                if i == 0:\n","                    dbranch7x7 = self._cn_bn_relu(filters=_d7x7r, kernel_size=(1, 7))(branch7x7)\n","                else :\n","                    dbranch7x7 = self._cn_bn_relu(filters=_d7x7, kernel_size=(1, 7))(branch7x7)\n","\n","\n","            return concatenate([branch1x1, branchpooling, branch7x7, dbranch7x7], axis = self.channel_axis, name = name)\n","\n","        return f\n","\n","\n","    def _GridSizeReduction17x17(self, _3x3r = 192, _3x3 =320, _d7x7x3r = 192, _d7x7x3 = 192):\n","        '''\n","        A function for dimension reducing from 17x17 -> 8x8\n","        '''\n","        def f(input_x):\n","\n","            branchpool = AveragePooling2D(pool_size = (3,3), strides = (2,2), padding = \"valid\")(input_x)\n","\n","            branch7x7 = self._cn_bn_relu(filters = _3x3r, kernel_size = (1,1))(input_x)\n","            branch7x7 = self._cn_bn_relu(filters = _3x3 , kernel_size = (3,3), strides = (2,2), padding = \"valid\")(branch7x7)\n","\n","            dbranch7x7 = self._cn_bn_relu(filters = _d7x7x3r, kernel_size = (1, 1))(input_x)\n","            dbranch7x7 = self._cn_bn_relu(filters = _d7x7x3, kernel_size = (7, 1))(dbranch7x7)\n","            dbranch7x7 = self._cn_bn_relu(filters = _d7x7x3, kernel_size = (1, 7))(dbranch7x7)\n","            dbranch7x7 = self._cn_bn_relu(filters = _d7x7x3,  kernel_size = (3, 3), strides = (2, 2), padding = \"valid\")(dbranch7x7)\n","\n","            return concatenate([branchpool, branch7x7, dbranch7x7], axis = self.channel_axis)\n","\n","        return f\n","\n","    def _inception_block8x8(self, _1x1 = 320, _pool = 192, _3x3r = 384, _3x3 = 384, _d3x3r = 448, _d3x3 = 384, name = \"inception_fig7_1\"):\n","        '''\n","        A function for building inception block of figure7 in original article,\n","        '''\n","\n","        def f(input_x):\n","\n","            branch1x1 = self._cn_bn_relu(filters = _1x1, kernel_size = (1,1))(input_x)\n","\n","            branchpool = AveragePooling2D(pool_size = (3,3), strides = (1,1), padding = \"same\")(input_x)\n","            branchpool = self._cn_bn_relu(filters = _pool, kernel_size = (1,1))(branchpool)\n","\n","            branch3x3 = self._cn_bn_relu(filters = _3x3r, kernel_size = (1,1))(input_x)\n","            branch3x3_1 = self._cn_bn_relu(filters = _3x3, kernel_size = (3,1))(branch3x3)\n","            branch3x3_2 = self._cn_bn_relu(filters = _3x3, kernel_size = (1,3))(branch3x3)\n","\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3r, kernel_size = (1,1))(input_x)\n","            dbranch3x3 = self._cn_bn_relu(filters = _d3x3, kernel_size = (3,3))(dbranch3x3)\n","            dbranch3x3_1 = self._cn_bn_relu(filters = _d3x3, kernel_size = (3,1))(dbranch3x3)\n","            dbranch3x3_2 = self._cn_bn_relu(filters = _d3x3, kernel_size = (1,3))(dbranch3x3)\n","\n","            return concatenate([branch1x1, branchpool, branch3x3_1, branch3x3_2, dbranch3x3_1, dbranch3x3_2], axis = self.channel_axis, name = name)\n","\n","        return f\n","\n","\n","    def build_inception(self):\n","\n","        '''\n","        Main function for building inceptionV3 nn\n","        :return: An inceptionV3 nn\n","        '''\n","\n","        input_x = Input(self.input_shape)\n","\n","\n","        #Few traditional convolutional layers at lower layers\n","        #Which are factorized by original 7x7 convolution layer\n","        x = self._cn_bn_relu(filters = 32, kernel_size = (3,3), strides = self.init_strides, padding = \"valid\")(input_x)\n","        x = self._cn_bn_relu(filters = 32, kernel_size = (3,3), strides = (1,1), padding = \"valid\")(x)\n","        x = self._cn_bn_relu(filters = 64, kernel_size = (3,3), strides=(1,1), padding=\"same\")(x)\n","\n","        if self.init_maxpooling:\n","            x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = \"valid\")(x)\n","\n","        x = self._cn_bn_relu(filters = 80, kernel_size = (3,3), strides=(1,1), padding = \"valid\")(x)\n","        x = self._cn_bn_relu(filters = 192, kernel_size = (3,3), strides = self.init_strides, padding = \"valid\")(x)\n","        x = self._cn_bn_relu(filters = 288, kernel_size = (3,3), strides = (1,1), padding = \"same\")(x)\n","\n","        #First 3 inception block, which are using architecture of figure5 in original article\n","        for i in range(3):\n","            x = self._inception_block35x35(_1x1=64,_3x3r=48,_3x3=64,_d3x3r=64,_d3x3=96, name = \"inception_fig5_\"+str(i+1))(x)\n","\n","        #Dimension reducing #1 (from 35x35 -> 17x17 in original article)\n","        x = self._GridSizeReduction35x35( _3x3r = 288, _3x3 = 384, _d3x3r = 64, _d3x3 = 96)(x)\n","\n","        # 5 inception block, which are using architecture of figure6 in original article\n","        for i in range(5):\n","            x = self._inception_block17x17(_1x1=192,_7x7r=128,_7x7=192,_d7x7r=128,_d7x7=192,_pool=192, name = \"inception_fig6_\"+str(i+1))(x)\n","\n","        # auxiliary classifier\n","        auxiliary = self._auxiliary(name = \"auxiliary_1\")(x)\n","\n","        #Dimension reducing #2 (from 17x17 -> 8x8 in original article)\n","        x = self._GridSizeReduction17x17(_3x3r=192,_3x3=320,_d7x7x3r=192,_d7x7x3=192)(x)\n","\n","        for i in range(2):\n","            x = self._inception_block8x8(_1x1 = 320, _pool = 192, _3x3r = 384, _3x3 = 384, _d3x3r = 448, _d3x3 = 384, name = \"inception_fig7_\"+str(i+1))(x)\n","\n","        x_shape = K.int_shape(x)\n","\n","        x = AveragePooling2D(pool_size = (x_shape[self.row_axis], x_shape[self.col_axis]), strides = (1,1))(x)\n","        x = Flatten()(x)\n","        x = Dense(units = 2048, kernel_initializer=self.initializer)(x)\n","        x = BatchNormalization(axis = 1)(x)\n","        x = Activation(\"relu\")(x)\n","\n","        output_x = Dense(units = 3, activation = \"softmax\", kernel_initializer=self.initializer,name = \"main_output\")(x)\n","\n","        inceptionv3_model = Model(inputs = [input_x], outputs = [output_x,auxiliary])\n","        return inceptionv3_model\n","\n","inception_builder = Inceptionv3_builder()\n","model = inception_builder.build_inception()\n","model.summary()\n","\n","model.compile(\n","    optimizer='Adam',\n","    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=[\"acc\"],\n",")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:46:30.933066Z","iopub.execute_input":"2022-01-09T12:46:30.933336Z","iopub.status.idle":"2022-01-09T12:46:35.678780Z","shell.execute_reply.started":"2022-01-09T12:46:30.933296Z","shell.execute_reply":"2022-01-09T12:46:35.678088Z"},"trusted":true,"id":"IpfAvgRNrPI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = []\n","label = []\n","x_validation = []\n","label_validation = []\n","x_test = []\n","label_test = []\n","\n","images = []\n","\n","#valid_covid = \"../input/radiography-dataset/new_Dataset/test/Covid\"\n","covid = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID\"\n","covid_list = os.listdir(covid)\n","\n","pneumonia = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia\"\n","pneumonia_list = os.listdir(pneumonia)\n","\n","normal = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal\"\n","normal_list = os.listdir(normal)\n","\n","\n","csv_file_link = \"../input/radiography-database-springer-2-image-division/division_into_train_valid__test.csv\"\n","csv_file = pd.read_csv(csv_file_link)\n","print(csv_file.columns)\n","\n","\n","group_by = csv_file.groupby('image_type')\n","for i,j in group_by:\n","    print(i)\n","    \n","    usedin_group_by = j.groupby('used_in')\n","    for k,l in usedin_group_by:\n","        print(k)\n","        print(len(l))\n","        for m in range(0, len(l)):\n","            if i == 'covid':\n","                    \n","                    link = covid + '/' + l.iloc[m]['image_name']\n","                    img = cv2.imread(link)\n","                    image = cv2.resize(img, ( img_size , img_size ))\n","                    if k == 'validation':\n","                        x_validation.append(image)\n","                        label_validation.append([0])\n","                    if k == 'test':\n","                        x_test.append(image)\n","                        label_test.append([0])\n","                    if k == 'train':\n","                        x.append(image)\n","                        label.append([0])\n","\n","                      \n","            if i == 'pneumonia':\n","                    \n","                    link = pneumonia + '/' + l.iloc[m]['image_name']\n","                    img = cv2.imread(link)\n","                    image = cv2.resize(img, ( img_size , img_size ))\n","                    if k == 'validation':\n","                        x_validation.append(image)\n","                        label_validation.append([1])\n","                    if k == 'test':\n","                        x_test.append(image)\n","                        label_test.append([1])\n","                    if k == 'train':\n","                        x.append(image)\n","                        label.append([1])\n","            \n","          \n","         \n","                        \n","                        \n","            if i == 'normal':\n","                    \n","                    link = normal + '/' + l.iloc[m]['image_name']\n","                    img = cv2.imread(link)\n","                    image = cv2.resize(img, ( img_size , img_size ))\n","                    if k == 'validation':\n","                        x_validation.append(image)\n","                        label_validation.append([2])\n","                    if k == 'test':\n","                        x_test.append(image)\n","                        label_test.append([2])\n","                    if k == 'train':\n","                        x.append(image)\n","                        label.append([2])\n","                    \n"," \n","                        \n","x = np.asarray(x)\n","print(len(x))\n","\n","\n","x_validation = np.asarray(x_validation)\n","print(len(x_validation))\n","\n","\n","\n","\n","x_test = np.asarray(x_test)\n","print(len(x_test))\n","\n","\n","\n","#label = np.array(label)\n","label = keras.utils.np_utils.to_categorical(label , 3 )\n","#print(label)\n","print(len(label))\n","\n","\n","#label = np.array(label)\n","label_validation = keras.utils.np_utils.to_categorical(label_validation , 3 )\n","#print(label_validation)\n","print(len(label_validation))\n","\n","\n","\n","#label_validation = np.array(label_validation)\n","label_test = keras.utils.np_utils.to_categorical(label_test , 3 )\n","#print(label_test)\n","print(len(label_test ))\n","\n","\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:46:35.680885Z","iopub.execute_input":"2022-01-09T12:46:35.681227Z","iopub.status.idle":"2022-01-09T12:48:54.325100Z","shell.execute_reply.started":"2022-01-09T12:46:35.681182Z","shell.execute_reply":"2022-01-09T12:48:54.320570Z"},"trusted":true,"id":"OR6U5lHlrPJC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_main_output_acc', patience= 90 , verbose=0, mode='max')\n","check_point = tf.keras.callbacks.ModelCheckpoint('./Inception_V3_Springer_paper_2.h5', monitor='val_main_output_acc', save_best_only=True, mode='max')\n","history = model.fit(x , label , validation_data = (x_validation, label_validation), epochs = 100, callbacks=[early_stop, check_point])\n","    \n","\n","print(\"skip\")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:48:54.330028Z","iopub.execute_input":"2022-01-09T12:48:54.330416Z","iopub.status.idle":"2022-01-09T15:16:31.199167Z","shell.execute_reply.started":"2022-01-09T12:48:54.330376Z","shell.execute_reply":"2022-01-09T15:16:31.196453Z"},"trusted":true,"id":"4rlqtJT-rPJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","with open('./Inception_V3_Springer_paper_2.pkl', 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","\n","print(\"pickle_dumped\")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:16:31.203234Z","iopub.execute_input":"2022-01-09T15:16:31.204563Z","iopub.status.idle":"2022-01-09T15:16:31.214568Z","shell.execute_reply.started":"2022-01-09T15:16:31.204518Z","shell.execute_reply":"2022-01-09T15:16:31.212639Z"},"trusted":true,"id":"vxX34ZxVrPJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert the history.history dict to a pandas DataFrame: \n","import pandas as pd\n","hist_df = pd.DataFrame(history.history) \n","\n","hist_csv_file = './Inception_V3_Springer_2.csv'\n","with open(hist_csv_file, mode='w') as f:\n","    hist_df.to_csv(f)\n","    \n","print(\"skip\")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:16:31.216872Z","iopub.execute_input":"2022-01-09T15:16:31.217390Z","iopub.status.idle":"2022-01-09T15:16:31.286651Z","shell.execute_reply.started":"2022-01-09T15:16:31.217352Z","shell.execute_reply":"2022-01-09T15:16:31.285920Z"},"trusted":true,"id":"2Bws5AoQrPJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_saved_model = tf.keras.models.load_model(\"./Inception_V3_Springer_paper_2.h5\")\n","#extract_saved_model.summary()\n","score = extract_saved_model.evaluate(x_test, label_test, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100 * score[6]))"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:17:36.165700Z","iopub.execute_input":"2022-01-09T15:17:36.165965Z","iopub.status.idle":"2022-01-09T15:17:45.002315Z","shell.execute_reply.started":"2022-01-09T15:17:36.165937Z","shell.execute_reply":"2022-01-09T15:17:45.001154Z"},"trusted":true,"id":"yNefkBaGrPJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['main_output_acc']\n","val_acc = history.history['val_main_output_acc']\n","\n","loss = history.history['main_output_loss']\n","val_loss = history.history['val_main_output_loss']\n","\n","epochs = 100\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 5))\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy Value', fontweight='bold', fontsize=11.0)\n","plt.xlabel('Epoch', fontweight='bold', fontsize=11.0)\n","#plt.title('Training and Validation Accuracy')\n","plt.savefig(\"Inception_V3_Accuracy.png\")\n","plt.show()\n"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:19:06.772677Z","iopub.execute_input":"2022-01-09T15:19:06.773178Z","iopub.status.idle":"2022-01-09T15:19:07.087489Z","shell.execute_reply.started":"2022-01-09T15:19:06.773141Z","shell.execute_reply":"2022-01-09T15:19:07.086843Z"},"trusted":true,"id":"0QUM9gT9rPJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8 , 5))\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Loss Value', fontweight='bold', fontsize=11.0)\n","plt.xlabel('Epoch', fontweight='bold', fontsize=11.0)\n","#plt.title('Training and Validation Loss')\n","plt.savefig(\"Inception_V2_loss.png\")\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:20:09.528816Z","iopub.execute_input":"2022-01-09T15:20:09.529181Z","iopub.status.idle":"2022-01-09T15:20:09.849011Z","shell.execute_reply.started":"2022-01-09T15:20:09.529147Z","shell.execute_reply":"2022-01-09T15:20:09.848329Z"},"trusted":true,"id":"Wq4UY0sArPJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while(True):\n","    i = 0 \n","    \n","    \n","    \n","    "],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:20:20.630012Z","iopub.execute_input":"2022-01-09T15:20:20.630378Z"},"trusted":true,"id":"fbKHqEOJrPJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9syuJz99rPJH"},"execution_count":null,"outputs":[]}]}