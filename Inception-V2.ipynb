{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n#from keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.utils.data_utils import get_file\n\nfrom keras.datasets import mnist\nfrom PIL import Image\n# for creating a one hot vector for labels\nfrom keras.utils import np_utils\nfrom IPython.display import display, Image\n#import the models\nfrom keras import Model\n#add layers\nfrom keras import layers\n#add optimizer\nfrom keras import optimizers\n#add loss function \nfrom keras import losses\n\nimport keras\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T11:35:02.907023Z","iopub.execute_input":"2022-01-09T11:35:02.907338Z","iopub.status.idle":"2022-01-09T11:35:08.760558Z","shell.execute_reply.started":"2022-01-09T11:35:02.907250Z","shell.execute_reply":"2022-01-09T11:35:08.759814Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Source : https://github.com/RayXie29/Keras-famous_CNN/blob/master/InceptionV2.py","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, BatchNormalization\nfrom keras.layers import Flatten, Input, Dropout, concatenate\nfrom keras.regularizers import  l2\nfrom keras import backend as K\nfrom keras.models import Model\n\nimg_size = 299\nclass Inceptionv2_builder():\n\n    def __init__(self, input_shape = (img_size, img_size, 3), output_units = 3, init_kernel = (7,7), init_strides = (2,2), init_filters = 64,\n                 regularizer = l2(1e-4), initializer = \"he_normal\", init_maxpooling = True):\n        '''\n        :param input_shape: input shape of dataset\n        :param output_units: output result dimension\n        :param init_kernel: The kernel size for first convolution layer\n        :param init_strides: The strides for first convolution layer\n        :param init_filters: The filter number for first convolution layer\n        :param regularizer: regularizer for all the convolution layers in whole NN\n        :param initializer: weight/parameters initializer for all convolution & fc layers in whole NN\n        :param init_maxpooling: Do the maxpooling after first two convolution layers or not\n        '''\n\n        assert len(input_shape) == 3, \"input shape should be dim 3 ( row, col, channel or channel row col )\"\n\n        self.input_shape = input_shape\n        self.output_units = output_units\n        self.init_kernel = init_kernel\n        self.init_strides = init_strides\n        self.init_filters = init_filters\n        self.regularizer = regularizer\n        self.initializer = initializer\n        self.init_maxpooling = init_maxpooling\n\n        #if K.image_dim_ordering() == \"tf\":\n\n        self.row_axis = 1\n        self.col_axis = 2\n        self.channel_axis = 3\n\n        \"\"\"\n        else:\n\n            self.row_axis = 2\n            self.col_axis = 3\n            self.channel_axis = 1\n        \"\"\"\n\n\n    def _cn_bn_relu(self, filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\",\n                    kernel_regularizer = l2(1e-4), kernel_initializer = \"he_normal\"):\n        '''\n        convenient function to build convolution -> batch normalization -> relu activation layers\n        '''\n        def f(input_x):\n\n            x = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding,\n                       kernel_initializer = kernel_initializer, kernel_regularizer = kernel_regularizer)(input_x)\n            x = BatchNormalization(axis = self.channel_axis)(x)\n            x = Activation(\"relu\")(x)\n\n            return x\n\n        return f\n\n    def _auxiliary(self, name = \"auxiliary_1\"):\n        '''\n        In author's explanation:\n        \" The auxiliary classifier will encourage discrimination in lower stages in the classifier,\n        increase the gradient signal that gets propagated back, and provide additional regularization\"\n        :return: An output layer of auxiliary classifier\n        '''\n        def f(input_x):\n\n            x = input_x\n            x = AveragePooling2D(pool_size=(5,5), strides = (3,3), padding = \"same\")(x)\n            x = self._cn_bn_relu(filters = 128, kernel_size = (1,1), padding = \"same\",\n                                 kernel_regularizer = self.regularizer, kernel_initializer = self.initializer)(x)\n            x = Flatten()(x)\n            x = Dense(units = 1024)(x)\n            x = BatchNormalization(axis = 1)(x)\n            x = Activation(\"relu\")(x)\n            x = Dropout(0.7)(x)\n\n            output = Dense(units = self.output_units, activation = \"softmax\", kernel_initializer = self.initializer, name = name)(x)\n            return output\n\n        return f\n\n\n    def _inception_block(self, _1x1 = 64, _3x3r = 96, _3x3 = 128, _d3x3r = 16, _d3x3 = 32,\n                         _pool = 32, strides = (1,1), pooling = \"avg\", name = \"inception3a\"):\n        '''\n        A function for building inception block, including 1x1 convolution layer, 3x3 convolution layer with dimension reducing,\n        double 3x3 convolution layers with dimension reducing and maxpooling layer with dimension reducing\n        :param _1x1: filter number of 1x1 convolution layer\n        :param _3x3r: filter number of dimension reducing layer for 3x3 convolution layer\n        :param _3x3: filter number of 3x3 convolution layer\n        :param _d3x3r: filter number of dimension reducing layer for double 3x3 convolution layers\n        :param _d3x3: filter number of double 3x3 convolution layers\n        :param _maxpool: filter number of dimension reducing layer for maxpooling layer\n        :return: A concatenate block of several scale convolution which is inception block\n        '''\n        def f(input_x):\n\n            branch1x1 = None\n            if _1x1 > 0:\n                branch1x1 = self._cn_bn_relu(filters=_1x1, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",\n                                             kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(input_x)\n\n            branch3x3 = self._cn_bn_relu(filters=_3x3r, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",\n                                         kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(input_x)\n            branch3x3 = self._cn_bn_relu(filters=_3x3, kernel_size=(3, 3), strides= strides, padding=\"same\",\n                                         kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(branch3x3)\n\n            dbranch3x3 = self._cn_bn_relu(filters=_d3x3r, kernel_size=(1, 1), strides = (1, 1), padding=\"same\",\n                                         kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(input_x)\n            dbranch3x3 = self._cn_bn_relu(filters=_d3x3, kernel_size=(3, 3), strides = (1, 1), padding=\"same\",\n                                         kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(dbranch3x3)\n            dbranch3x3 = self._cn_bn_relu(filters=_d3x3, kernel_size=(3, 3), strides = strides, padding=\"same\",\n                                          kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(dbranch3x3)\n\n            brancemaxpool = None\n            if pooling == \"avg\":\n                brancemaxpool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding=\"same\")(input_x)\n                brancemaxpool = self._cn_bn_relu(filters=_pool, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",\n                                                 kernel_regularizer=self.regularizer, kernel_initializer=self.initializer)(brancemaxpool)\n            else:\n                brancemaxpool = MaxPooling2D(pool_size=(3,3), strides = strides, padding = \"same\")(input_x)\n\n            if _1x1 > 0:\n                return concatenate([branch1x1, branch3x3, dbranch3x3, brancemaxpool], axis=self.channel_axis, name = name)\n            else :\n                return concatenate([branch3x3, dbranch3x3, brancemaxpool], axis=self.channel_axis, name = name)\n\n        return f\n\n    def build_inception(self):\n\n        '''\n        Main function for building inceptionV2 nn\n        :return: An inceptionV2 nn\n        '''\n\n        #Few traditional convolutional layers at lower layers\n        input_x = Input(self.input_shape)\n        x = self._cn_bn_relu(filters = self.init_filters, kernel_size = self.init_kernel, strides = self.init_strides,\n                             kernel_regularizer = self.regularizer, kernel_initializer = self.initializer)(input_x)\n\n        if self.init_maxpooling:\n            x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = \"same\")(x)\n\n        x = self._cn_bn_relu(filters = 192, kernel_size = (3,3), strides = (1, 1), padding = \"same\",\n                             kernel_regularizer = self.regularizer, kernel_initializer = self.initializer)(x)\n\n        if self.init_maxpooling:\n            x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = \"same\")(x)\n\n\n\n        #inception(3a)\n        x = self._inception_block(_1x1=64, _3x3r=64, _3x3=64, _d3x3r=64, _d3x3=96, _pool=32, name = \"inception3a\")(x)\n\n        #inception(3b)\n        x = self._inception_block(_1x1=64, _3x3r=64, _3x3=96, _d3x3r=64, _d3x3=96, _pool=64, name = \"inception3b\")(x)\n\n        #inception(3c)\n        x = self._inception_block(_1x1=0, _3x3r=128, _3x3=160, _d3x3r=64, _d3x3=96,_pool=0,\n                                  name = \"inception3c\", strides=(2,2),pooling=\"max\")(x)\n\n        #inception(4a)\n        x = self._inception_block(_1x1=224, _3x3r=64, _3x3=96, _d3x3r=96, _d3x3=128, _pool=128, name = \"inception4a\")(x)\n\n        #auxiliary classifier 1\n        auxiliary1 = self._auxiliary(name = \"auxiliary_1\")(x)\n\n        # inception(4b)\n        x = self._inception_block(_1x1=192, _3x3r=96, _3x3=128, _d3x3r=96, _d3x3=128, _pool=128, name = \"inception4b\")(x)\n        # inception(4c)\n        x = self._inception_block(_1x1=160, _3x3r=96, _3x3=128, _d3x3r=128, _d3x3=160, _pool=128, name = \"inception4c\")(x)\n        # inception(4d)\n        x = self._inception_block(_1x1=96, _3x3r=128, _3x3=160, _d3x3r=160, _d3x3=192, _pool=128, name = \"inception4d\")(x)\n\n        #auxiliary classifier 2\n        auxiliary2 = self._auxiliary(name = \"auxiliary_2\")(x)\n\n        # inception(4e)\n        x = self._inception_block(_1x1=0, _3x3r=128, _3x3=192, _d3x3r=192, _d3x3=256, _pool=0,\n                                  name = \"inception4e\", strides = (2,2), pooling = \"max\")(x)\n\n        #inception(5a)\n        x = self._inception_block(_1x1=352, _3x3r=192, _3x3=320, _d3x3r=160, _d3x3=224, _pool=128, name = \"inception5a\")(x)\n        #inception(5b)\n        x = self._inception_block(_1x1=352, _3x3r=192, _3x3=320, _d3x3r=192, _d3x3=224, _pool=128, name = \"inception5b\")(x)\n\n        x_shape = K.int_shape(x)\n        x = AveragePooling2D(pool_size = (x_shape[self.row_axis], x_shape[self.col_axis]), strides=(1,1))(x)\n        x = Flatten()(x)\n        x = Dropout(0.4)(x)\n        x = Dense(units = 1000, kernel_initializer = self.initializer)(x)\n        x = BatchNormalization(axis = 1)(x)\n        x = Activation(\"relu\")(x)\n        output_x = Dense(units = self.output_units, activation = \"softmax\", kernel_initializer=self.initializer, name = \"main_output\")(x)\n\n        inceptionv2_model = Model(inputs = [input_x], outputs = [auxiliary1, auxiliary2, output_x])\n\n        return inceptionv2_model\n\n\ninception_builder = Inceptionv2_builder()\nmodel = inception_builder.build_inception()\nmodel.compile(\n    optimizer='Adam',\n    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n    metrics=[\"acc\"],\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:35:08.762508Z","iopub.execute_input":"2022-01-09T11:35:08.762799Z","iopub.status.idle":"2022-01-09T11:35:12.621032Z","shell.execute_reply.started":"2022-01-09T11:35:08.762763Z","shell.execute_reply":"2022-01-09T11:35:12.620350Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"x = []\nlabel = []\nx_validation = []\nlabel_validation = []\nx_test = []\nlabel_test = []\n\nimages = []\n\n#valid_covid = \"../input/radiography-dataset/new_Dataset/test/Covid\"\ncovid = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID\"\ncovid_list = os.listdir(covid)\n\npneumonia = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia\"\npneumonia_list = os.listdir(pneumonia)\n\nnormal = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal\"\nnormal_list = os.listdir(normal)\n\n\ncsv_file_link = \"../input/radiography-database-springer-2-image-division/division_into_train_valid__test.csv\"\ncsv_file = pd.read_csv(csv_file_link)\nprint(csv_file.columns)\n\n\ngroup_by = csv_file.groupby('image_type')\nfor i,j in group_by:\n    print(i)\n    \n    usedin_group_by = j.groupby('used_in')\n    for k,l in usedin_group_by:\n        print(k)\n        print(len(l))\n        for m in range(0, len(l)):\n            if i == 'covid':\n                    \n                    link = covid + '/' + l.iloc[m]['image_name']\n                    img = cv2.imread(link)\n                    image = cv2.resize(img, ( img_size , img_size ))\n                    if k == 'validation':\n                        x_validation.append(image)\n                        label_validation.append([0])\n                    if k == 'test':\n                        x_test.append(image)\n                        label_test.append([0])\n                    if k == 'train':\n                        x.append(image)\n                        label.append([0])\n\n                       \n            if i == 'pneumonia':\n                    \n                    link = pneumonia + '/' + l.iloc[m]['image_name']\n                    img = cv2.imread(link)\n                    image = cv2.resize(img, ( img_size , img_size ))\n                    if k == 'validation':\n                        x_validation.append(image)\n                        label_validation.append([1])\n                    if k == 'test':\n                        x_test.append(image)\n                        label_test.append([1])\n                    if k == 'train':\n                        x.append(image)\n                        label.append([1])\n            \n          \n         \n                        \n                        \n            if i == 'normal':\n                    \n                    link = normal + '/' + l.iloc[m]['image_name']\n                    img = cv2.imread(link)\n                    image = cv2.resize(img, ( img_size , img_size ))\n                    if k == 'validation':\n                        x_validation.append(image)\n                        label_validation.append([2])\n                    if k == 'test':\n                        x_test.append(image)\n                        label_test.append([2])\n                    if k == 'train':\n                        x.append(image)\n                        label.append([2])\n                    \n \n                        \nx = np.asarray(x)\nprint(len(x))\n\n\nx_validation = np.asarray(x_validation)\nprint(len(x_validation))\n\n\n\n\nx_test = np.asarray(x_test)\nprint(len(x_test))\n\n\n\n#label = np.array(label)\nlabel = keras.utils.np_utils.to_categorical(label , 3 )\n#print(label)\nprint(len(label))\n\n\n#label = np.array(label)\nlabel_validation = keras.utils.np_utils.to_categorical(label_validation , 3 )\n#print(label_validation)\nprint(len(label_validation))\n\n\n\n#label_validation = np.array(label_validation)\nlabel_test = keras.utils.np_utils.to_categorical(label_test , 3 )\n#print(label_test)\nprint(len(label_test ))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:35:12.622570Z","iopub.execute_input":"2022-01-09T11:35:12.622835Z","iopub.status.idle":"2022-01-09T11:36:56.921480Z","shell.execute_reply.started":"2022-01-09T11:35:12.622801Z","shell.execute_reply":"2022-01-09T11:36:56.920026Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_main_output_acc', patience= 90, verbose=0, mode='max')\ncheck_point = tf.keras.callbacks.ModelCheckpoint('./Inception_V2_Springer_paper_2.h5', monitor='val_main_output_acc', save_best_only=True, mode='max')\nhistory = model.fit(x , label , validation_data = (x_validation, label_validation), epochs = 100, callbacks=[early_stop, check_point])\n    \n\nprint(\"skip\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:36:56.923727Z","iopub.execute_input":"2022-01-09T11:36:56.923995Z","iopub.status.idle":"2022-01-09T13:22:32.699891Z","shell.execute_reply.started":"2022-01-09T11:36:56.923959Z","shell.execute_reply":"2022-01-09T13:22:32.698210Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open('./Inception_V2_Springer_paper_2.pkl', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n\nprint(\"pickle_dumped\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:22:32.704996Z","iopub.execute_input":"2022-01-09T13:22:32.705205Z","iopub.status.idle":"2022-01-09T13:22:32.712599Z","shell.execute_reply.started":"2022-01-09T13:22:32.705179Z","shell.execute_reply":"2022-01-09T13:22:32.711621Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# convert the history.history dict to a pandas DataFrame: \nimport pandas as pd\nhist_df = pd.DataFrame(history.history) \n\nhist_csv_file = './Inception_V2_Springer_2.csv'\nwith open(hist_csv_file, mode='w') as f:\n    hist_df.to_csv(f)\n    \nprint(\"skip\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:22:32.714171Z","iopub.execute_input":"2022-01-09T13:22:32.714484Z","iopub.status.idle":"2022-01-09T13:22:32.778022Z","shell.execute_reply.started":"2022-01-09T13:22:32.714449Z","shell.execute_reply":"2022-01-09T13:22:32.777328Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"extract_saved_model = tf.keras.models.load_model(\"./Inception_V2_Springer_paper_2.h5\")\n#extract_saved_model.summary()\nscore = extract_saved_model.evaluate(x_test, label_test, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * score[6]))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:22:32.779109Z","iopub.execute_input":"2022-01-09T13:22:32.779348Z","iopub.status.idle":"2022-01-09T13:22:40.931391Z","shell.execute_reply.started":"2022-01-09T13:22:32.779314Z","shell.execute_reply":"2022-01-09T13:22:40.930703Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"acc = history.history['main_output_acc']\nval_acc = history.history['val_main_output_acc']\n\nloss = history.history['main_output_loss']\nval_loss = history.history['val_main_output_loss']\n\nepochs = 100\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 5))\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.savefig(\"Inception_V2_Accuracy.png\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:22:40.934467Z","iopub.execute_input":"2022-01-09T13:22:40.934667Z","iopub.status.idle":"2022-01-09T13:22:41.265695Z","shell.execute_reply.started":"2022-01-09T13:22:40.934641Z","shell.execute_reply":"2022-01-09T13:22:41.265011Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8 , 5))\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.savefig(\"Inception_V2_loss.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:22:41.271006Z","iopub.execute_input":"2022-01-09T13:22:41.271492Z","iopub.status.idle":"2022-01-09T13:22:41.515191Z","shell.execute_reply.started":"2022-01-09T13:22:41.271452Z","shell.execute_reply":"2022-01-09T13:22:41.514530Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"while(True):\n    i = 0 \n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:22:41.518389Z","iopub.execute_input":"2022-01-09T13:22:41.518580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}