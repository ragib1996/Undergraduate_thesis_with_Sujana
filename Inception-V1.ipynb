{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"inception-v1-springer-paper-2.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["from tensorflow import keras\n","from keras.models import Model\n","from keras import layers\n","from keras.layers import Dense, Input, BatchNormalization, Activation\n","from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n","#from keras.applications.imagenet_utils import _obtain_input_shape\n","from keras.utils.data_utils import get_file\n","\n","from keras.datasets import mnist\n","from PIL import Image\n","# for creating a one hot vector for labels\n","from keras.utils import np_utils\n","from IPython.display import display, Image\n","#import the models\n","from keras import Model\n","#add layers\n","from keras import layers\n","#add optimizer\n","from keras import optimizers\n","#add loss function \n","from keras import losses\n","\n","import keras\n","import numpy as np\n","import pandas as pd \n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n"," "],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T11:11:42.763762Z","iopub.execute_input":"2022-01-09T11:11:42.764061Z","iopub.status.idle":"2022-01-09T11:11:48.744334Z","shell.execute_reply.started":"2022-01-09T11:11:42.763982Z","shell.execute_reply":"2022-01-09T11:11:48.743559Z"},"trusted":true,"id":"0zGtYRXwq1Ty"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Source : https://github.com/RayXie29/Keras-famous_CNN/blob/master/InceptionV1.py"],"metadata":{"id":"NwqxgCfcq6Do"}},{"cell_type":"code","source":["\"\"\"\n","Skip to content\n","Search or jump toâ€¦\n","\n","Pull requests\n","Issues\n","Marketplace\n","Explore\n"," \n","@ragib1996 \n","RayXie29\n","/\n","Keras-famous_CNN\n","1\n","84\n","Code\n","Issues\n","Pull requests\n","Actions\n","Projects\n","Wiki\n","Security\n","Insights\n","Keras-famous_CNN/InceptionV1.py /\n","@RayXie29\n","RayXie29 add inception block name\n","Latest commit f13c804 on Aug 11, 2019\n"," History\n"," 1 contributor\n","181 lines (132 sloc)  8.03 KB\n","\"\"\"\n","import keras\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.layers import Dense, Activation\n","from keras.layers import Flatten, Input, Dropout, concatenate\n","from keras.regularizers import  l2\n","from keras import backend as K\n","from keras.models import Model\n","\n","img_size = 299\n","\n","class Inceptionv1_builder():\n","\n","    def __init__(self, input_shape = (img_size, img_size ,3), output_units = 3, init_kernel = (7,7), init_strides = (2,2), init_filters = 64,\n","                 regularizer = l2(1e-4), initializer = \"he_normal\", init_maxpooling = True):\n","        '''\n","        :param input_shape: input shape of dataset\n","        :param output_units: output result dimension\n","        :param init_kernel: The kernel size for first convolution layer\n","        :param init_strides: The strides for first convolution layer\n","        :param init_filters: The filter number for first convolution layer\n","        :param regularizer: regularizer for all the convolution layers in whole NN\n","        :param initializer: weight/parameters initializer for all convolution & fc layers in whole NN\n","        :param init_maxpooling: Do the maxpooling after first two convolution layers or not\n","        '''\n","\n","        assert len(input_shape) == 3, \"input shape should be dim 3 ( row, col, channel or channel row col )\"\n","\n","        self.input_shape = input_shape\n","        self.output_units = output_units\n","        self.init_kernel = init_kernel\n","        self.init_strides = init_strides\n","        self.init_filters = init_filters\n","        self.regularizer = regularizer\n","        self.initializer = initializer\n","        self.init_maxpooling = init_maxpooling\n","\n","        #if K.image_dim_ordering() == \"tf\":\n","\n","        self.row_axis = 1\n","        self.col_axis = 2\n","        self.channel_axis = 3\n","\n","        \"\"\"\n","        else:\n","\n","            self.row_axis = 2\n","            self.col_axis = 3\n","            self.channel_axis = 1\n","        \"\"\"\n","\n","\n","    def _cn_relu(self, filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\"):\n","        '''\n","        convenient function to build convolution(with regularizer and initializer) -> relu activation layers\n","        '''\n","        def f(input_x):\n","\n","            x = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding,activation=\"relu\",\n","                       kernel_initializer = self.initializer , kernel_regularizer = self.regularizer)(input_x)\n","            return x\n","\n","        return f\n","\n","    def _auxiliary(self, name = \"auxiliary_1\"):\n","        '''\n","        In author's explanation:\n","        \" The auxiliary classifier will encourage discrimination in lower stages in the classifier,\n","        increase the gradient signal that gets propagated back, and provide additional regularization\"\n","        :return: An output layer of auxiliary classifier\n","        '''\n","        def f(input_x):\n","\n","            x = input_x\n","            x = AveragePooling2D(pool_size=(5,5), strides = (3,3), padding = \"same\")(x)\n","            x = self._cn_relu(filters = 128, kernel_size = (1,1), padding = \"same\")(x)\n","            x = Flatten()(x)\n","            x = Dense(units = 1024, activation = \"relu\", kernel_regularizer= self.regularizer)(x)\n","            x = Dropout(0.7)(x)\n","\n","            return Dense(units = self.output_units, activation = \"softmax\", kernel_initializer=self.initializer, name = name)(x)\n","\n","        return f\n","\n","\n","    def _inception_block(self, _1x1 = 64, _3x3r = 96, _3x3 = 128, _5x5r = 16, _5x5 = 32, _maxpool = 32, name = \"inception3a\"):\n","        '''\n","        A function for building inception block, including 1x1 convolution layer, 3x3 convolution layer with dimension reducing,\n","        5x5 convolution layer with dimension reducing and maxpooling layer with dimension reducing\n","        :param _1x1: filter number of 1x1 convolution layer\n","        :param _3x3r: filter number of dimension reducing layer for 3x3 convolution layer\n","        :param _3x3: filter number of 3x3 convolution layer\n","        :param _5x5r: filter number of dimension reducing layer for 5x5 convolution layer\n","        :param _5x5: filter number of 5x5 convolution layer\n","        :param _maxpool: filter number of dimension reducing layer for maxpooling layer\n","        :return: A concatenate block of several scale convolution which is inception block\n","        '''\n","        def f(input_x):\n","\n","            branch1x1 = self._cn_relu(filters=_1x1, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(input_x)\n","\n","            branch3x3 = self._cn_relu(filters=_3x3r, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(input_x)\n","            branch3x3 = self._cn_relu(filters=_3x3, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(branch3x3)\n","\n","            branch5x5 = self._cn_relu(filters=_5x5r, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(input_x)\n","            branch5x5 = self._cn_relu(filters=_5x5, kernel_size=(5, 5), strides=(1, 1), padding=\"same\",)(branch5x5)\n","\n","            brancemaxpool = MaxPooling2D(pool_size = (3,3), strides = (1,1), padding = \"same\")(input_x)\n","            brancemaxpool = self._cn_relu(filters=_maxpool, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(brancemaxpool)\n","\n","            return concatenate([branch1x1,branch3x3,branch5x5,brancemaxpool], axis = self.channel_axis, name = name)\n","\n","        return f\n","    def build_inception(self):\n","\n","        '''\n","        Main function for building inceptionV1 nn\n","        :return: An inceptionV1 nn\n","        '''\n","\n","        #Few traditional convolutional layers at lower layers\n","        input_x = Input(self.input_shape)\n","\n","        x = self._cn_relu(filters = self.init_filters, kernel_size = self.init_kernel, strides = self.init_strides, padding = \"same\")(input_x)\n","\n","        if self.init_maxpooling:\n","            x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = \"same\")(x)\n","\n","        x = self._cn_relu(filters = 192, kernel_size = (3,3), strides = (1, 1), padding = \"same\")(x)\n","\n","        if self.init_maxpooling:\n","            x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = \"same\")(x)\n","\n","        #inception(3a)\n","        x = self._inception_block(_1x1=64, _3x3r=96, _3x3=128, _5x5r=16, _5x5=32, _maxpool=32, name = \"inception3a\")(x)\n","\n","        #inception(3b)\n","        x = self._inception_block(_1x1=128, _3x3r=128, _3x3=192, _5x5r=32, _5x5=96, _maxpool=64, name = \"inception3b\")(x)\n","\n","        x = MaxPooling2D(pool_size=(3,3), strides = (2,2), padding = \"same\")(x)\n","\n","        #inception(4a)\n","        x = self._inception_block(_1x1=192, _3x3r=96, _3x3=208, _5x5r=16, _5x5=48, _maxpool=64, name = \"inception4a\")(x)\n","\n","        #auxiliary classifier 1\n","        auxiliary1 = self._auxiliary(name = \"auxiliary_1\")(x)\n","\n","        # inception(4b)\n","        x = self._inception_block(_1x1=160, _3x3r=112, _3x3=224, _5x5r=24, _5x5=64, _maxpool=64, name = \"inception4b\")(x)\n","        # inception(4c)\n","        x = self._inception_block(_1x1=128, _3x3r=128, _3x3=256, _5x5r=24, _5x5=64, _maxpool=64, name = \"inception4c\")(x)\n","        # inception(4d)\n","        x = self._inception_block(_1x1=112, _3x3r=144, _3x3=288, _5x5r=32, _5x5=64, _maxpool=64, name = \"inception4d\")(x)\n","\n","        #auxiliary classifier 2\n","        auxiliary2 = self._auxiliary(name = \"auxiliary_2\")(x)\n","\n","        # inception(4e)\n","        x = self._inception_block(_1x1=256, _3x3r=160, _3x3=320, _5x5r=32, _5x5=128, _maxpool=128, name = \"inception4e\")(x)\n","\n","        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding = \"same\")(x)\n","\n","        #inception(5a)\n","        x = self._inception_block(_1x1=256, _3x3r=160, _3x3=320, _5x5r=32, _5x5=128, _maxpool=128, name = \"inception5a\")(x)\n","        #inception(5b)\n","        x = self._inception_block(_1x1=384, _3x3r=192, _3x3=384, _5x5r=48, _5x5=128, _maxpool=128, name = \"inception5b\")(x)\n","\n","        x_shape = K.int_shape(x)\n","        x = AveragePooling2D(pool_size = (x_shape[self.row_axis], x_shape[self.col_axis]), strides=(1,1))(x)\n","        x = Flatten()(x)\n","        x = Dropout(0.4)(x)\n","        x = Dense(units = 1000, kernel_initializer = self.initializer, activation=\"relu\")(x)\n","        output_x = Dense(units = self.output_units, activation = \"softmax\", kernel_initializer=self.initializer, name = \"main_output\")(x)\n","\n","        inceptionv1_model = Model(inputs = [input_x], outputs = [auxiliary1, auxiliary2, output_x])\n","\n","        return inceptionv1_model\n","\n","\n","inception_builder = Inceptionv1_builder()\n","model = inception_builder.build_inception()\n","model.compile(\n","    optimizer= 'Adam',\n","    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=[\"acc\"],\n",")\n","model.summary()\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:11:48.746056Z","iopub.execute_input":"2022-01-09T11:11:48.746291Z","iopub.status.idle":"2022-01-09T11:11:51.616282Z","shell.execute_reply.started":"2022-01-09T11:11:48.746258Z","shell.execute_reply":"2022-01-09T11:11:51.615543Z"},"trusted":true,"id":"65OwHl89q1T3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = []\n","label = []\n","x_validation = []\n","label_validation = []\n","x_test = []\n","label_test = []\n","\n","images = []\n","\n","#valid_covid = \"../input/radiography-dataset/new_Dataset/test/Covid\"\n","covid = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID\"\n","covid_list = os.listdir(covid)\n","\n","pneumonia = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia\"\n","pneumonia_list = os.listdir(pneumonia)\n","\n","normal = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal\"\n","normal_list = os.listdir(normal)\n","\n","\n","csv_file_link = \"../input/radiography-database-springer-2-image-division/division_into_train_valid__test.csv\"\n","csv_file = pd.read_csv(csv_file_link)\n","print(csv_file.columns)\n","\n","\n","group_by = csv_file.groupby('image_type')\n","for i,j in group_by:\n","    print(i)\n","    \n","    usedin_group_by = j.groupby('used_in')\n","    for k,l in usedin_group_by:\n","        print(k)\n","        print(len(l))\n","        for m in range(0, len(l)):\n","            if i == 'covid':\n","                    \n","                    link = covid + '/' + l.iloc[m]['image_name']\n","                    img = cv2.imread(link)\n","                    image = cv2.resize(img, ( img_size , img_size ))\n","                    if k == 'validation':\n","                        x_validation.append(image)\n","                        label_validation.append([0])\n","                    if k == 'test':\n","                        x_test.append(image)\n","                        label_test.append([0])\n","                    if k == 'train':\n","                        x.append(image)\n","                        label.append([0])\n","\n","                      \n","            if i == 'pneumonia':\n","                    \n","                    link = pneumonia + '/' + l.iloc[m]['image_name']\n","                    img = cv2.imread(link)\n","                    image = cv2.resize(img, ( img_size , img_size ))\n","                    if k == 'validation':\n","                        x_validation.append(image)\n","                        label_validation.append([1])\n","                    if k == 'test':\n","                        x_test.append(image)\n","                        label_test.append([1])\n","                    if k == 'train':\n","                        x.append(image)\n","                        label.append([1])\n","            \n","          \n","         \n","                        \n","                        \n","            if i == 'normal':\n","                    \n","                    link = normal + '/' + l.iloc[m]['image_name']\n","                    img = cv2.imread(link)\n","                    image = cv2.resize(img, ( img_size , img_size ))\n","                    if k == 'validation':\n","                        x_validation.append(image)\n","                        label_validation.append([2])\n","                    if k == 'test':\n","                        x_test.append(image)\n","                        label_test.append([2])\n","                    if k == 'train':\n","                        x.append(image)\n","                        label.append([2])\n","                    \n"," \n","                        \n","x = np.asarray(x)\n","print(len(x))\n","\n","\n","x_validation = np.asarray(x_validation)\n","print(len(x_validation))\n","\n","\n","\n","\n","x_test = np.asarray(x_test)\n","print(len(x_test))\n","\n","\n","\n","#label = np.array(label)\n","label = keras.utils.np_utils.to_categorical(label , 3 )\n","#print(label)\n","print(len(label))\n","\n","\n","#label = np.array(label)\n","label_validation = keras.utils.np_utils.to_categorical(label_validation , 3 )\n","#print(label_validation)\n","print(len(label_validation))\n","\n","\n","\n","#label_validation = np.array(label_validation)\n","label_test = keras.utils.np_utils.to_categorical(label_test , 3 )\n","#print(label_test)\n","print(len(label_test ))\n","\n","\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:11:51.617464Z","iopub.execute_input":"2022-01-09T11:11:51.617723Z","iopub.status.idle":"2022-01-09T11:13:47.161935Z","shell.execute_reply.started":"2022-01-09T11:11:51.617690Z","shell.execute_reply":"2022-01-09T11:13:47.161190Z"},"trusted":true,"id":"layvJf-Hq1T6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_main_output_acc', patience= 5, verbose=0, mode='max')\n","check_point = tf.keras.callbacks.ModelCheckpoint('./Inception_V1_Springer_paper_2.h5', monitor='val_main_output_acc', save_best_only=True, mode='max')\n","history = model.fit(x , label , validation_data = (x_validation, label_validation), epochs = 7, callbacks=[early_stop, check_point])\n","    \n","\n","print(\"skip\")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:13:47.164080Z","iopub.execute_input":"2022-01-09T11:13:47.164314Z","iopub.status.idle":"2022-01-09T11:20:18.530947Z","shell.execute_reply.started":"2022-01-09T11:13:47.164282Z","shell.execute_reply":"2022-01-09T11:20:18.529182Z"},"trusted":true,"id":"nQbOXNWIq1T7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","with open('./Inception_V1_Springer_paper_2.pkl', 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","\n","print(\"pickle_dumped\")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:20:18.533189Z","iopub.execute_input":"2022-01-09T11:20:18.534572Z","iopub.status.idle":"2022-01-09T11:20:18.541002Z","shell.execute_reply.started":"2022-01-09T11:20:18.534530Z","shell.execute_reply":"2022-01-09T11:20:18.539888Z"},"trusted":true,"id":"CvfprO2aq1T7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert the history.history dict to a pandas DataFrame: \n","import pandas as pd\n","hist_df = pd.DataFrame(history.history) \n","\n","hist_csv_file = './Inception_V1_Springer_2.csv'\n","with open(hist_csv_file, mode='w') as f:\n","    hist_df.to_csv(f)\n","    \n","print(\"skip\")"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:20:18.542177Z","iopub.execute_input":"2022-01-09T11:20:18.542618Z","iopub.status.idle":"2022-01-09T11:20:18.568620Z","shell.execute_reply.started":"2022-01-09T11:20:18.542579Z","shell.execute_reply":"2022-01-09T11:20:18.567875Z"},"trusted":true,"id":"hIqSHmVEq1T8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_saved_model = tf.keras.models.load_model(\"./Inception_V1_Springer_paper_2.h5\")\n","#extract_saved_model.summary()\n","score = extract_saved_model.evaluate(x_test, label_test, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100 * score[6]))"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:20:18.569966Z","iopub.execute_input":"2022-01-09T11:20:18.570438Z","iopub.status.idle":"2022-01-09T11:20:23.433973Z","shell.execute_reply.started":"2022-01-09T11:20:18.570400Z","shell.execute_reply":"2022-01-09T11:20:23.433163Z"},"trusted":true,"id":"qInfHV5mq1T8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['main_output_acc']\n","val_acc = history.history['val_main_output_acc']\n","\n","loss = history.history['main_output_loss']\n","val_loss = history.history['val_main_output_loss']\n","\n","epochs = 7\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 5))\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","plt.savefig(\"Inception_V2_Accuracy.png\")\n","plt.show()\n"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:20:31.811212Z","iopub.execute_input":"2022-01-09T11:20:31.811731Z","iopub.status.idle":"2022-01-09T11:20:32.067374Z","shell.execute_reply.started":"2022-01-09T11:20:31.811695Z","shell.execute_reply":"2022-01-09T11:20:32.066732Z"},"trusted":true,"id":"_tDLpC2Jq1T9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8 , 5))\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.savefig(\"Inception_V2_loss.png\")\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:20:38.131478Z","iopub.execute_input":"2022-01-09T11:20:38.132158Z","iopub.status.idle":"2022-01-09T11:20:38.696872Z","shell.execute_reply.started":"2022-01-09T11:20:38.132122Z","shell.execute_reply":"2022-01-09T11:20:38.696184Z"},"trusted":true,"id":"rUe_HbPIq1T-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while(True):\n","    i = 0 \n","    \n","    \n","    \n","    "],"metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:20:24.400063Z","iopub.status.idle":"2022-01-09T11:20:24.400732Z","shell.execute_reply.started":"2022-01-09T11:20:24.400468Z","shell.execute_reply":"2022-01-09T11:20:24.400517Z"},"trusted":true,"id":"u9Fs0lanq1T_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"13aIqSrXq1T_"},"execution_count":null,"outputs":[]}]}